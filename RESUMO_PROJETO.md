# Sistema de Reconhecimento de Golpes de T√™nis

**Resumo executivo do projeto - Vers√£o em Portugu√™s**

---

## Vis√£o Geral do Projeto

Este projeto implementa um sistema completo de reconhecimento autom√°tico de golpes de t√™nis usando **estima√ß√£o de pose** (MediaPipe) e **redes neurais LSTM**. O sistema √© capaz de identificar diferentes tipos de golpes (forehand, backhand, saque, slices) em v√≠deos cont√≠nuos de partidas de t√™nis.

### Objetivo Principal

Detectar e classificar automaticamente golpes de t√™nis em v√≠deos, gerando:
- Timeline visual dos golpes detectados
- Estat√≠sticas de frequ√™ncia de cada tipo de golpe
- Relat√≥rios detalhados com timestamps
- Dados exportados em JSON para an√°lises posteriores

---

## Como o Sistema Funciona

### Pipeline Completo

```
V√≠deo de T√™nis
    ‚Üì
[1] Extra√ß√£o de Pose (MediaPipe)
    - Detecta 33 pontos do corpo (ombros, cotovelos, pulsos, quadris, etc.)
    - Gera 132 features por frame (x, y, z, visibilidade)
    ‚Üì
[2] Cria√ß√£o de Sequ√™ncias
    - Janelas deslizantes de 45 frames (~1.5 segundos)
    - Sobreposi√ß√£o de 50% para melhor detec√ß√£o
    ‚Üì
[3] Classifica√ß√£o LSTM
    - Rede neural aprende padr√µes temporais do movimento
    - Reconhece sequ√™ncias espec√≠ficas de cada golpe
    ‚Üì
[4] P√≥s-processamento
    - Filtragem por confian√ßa
    - Mesclagem de detec√ß√µes pr√≥ximas
    - Gera√ß√£o de timeline e relat√≥rios
    ‚Üì
Resultado: Golpes identificados com timestamps
```

---

## Arquitetura do Modelo

### Por Que LSTM?

Golpes de t√™nis s√£o **sequ√™ncias temporais** de movimentos corporais:
- **Prepara√ß√£o** (backswing): frames 0-15
- **Acelera√ß√£o** (forward swing): frames 15-30
- **Contato**: frame ~25
- **Finaliza√ß√£o** (follow-through): frames 30-45

**LSTM** (Long Short-Term Memory) √© ideal porque:
- ‚úÖ Lembra frames anteriores ao processar frames seguintes
- ‚úÖ Aprende padr√µes de movimento ao longo do tempo
- ‚úÖ Captura a sequ√™ncia completa do golpe

### Arquitetura da Rede Neural

```
Entrada: (45 frames, 132 features) = Sequ√™ncia de 1.5 segundos de movimento

    ‚Üì
[LSTM Layer 1] - 64 unidades
    ‚Üì Dropout 0.4
[LSTM Layer 2] - 128 unidades
    ‚Üì Dropout 0.4
[LSTM Layer 3] - 64 unidades
    ‚Üì Dropout 0.3
[Dense Layer] - 64 unidades
    ‚Üì Dropout 0.3
[Dense Layer] - 64 unidades
    ‚Üì Dropout 0.2
[Output] - num_classes (softmax)

Sa√≠da: Probabilidades [P(forehand), P(backhand), P(saque), ...]
```

**Exemplo de sa√≠da**: `[0.08, 0.92]` ‚Üí 92% forehand, 8% backhand

---

## Caracter√≠sticas Principais

### 1. Extra√ß√£o e Cache de Poses

**Problema**: Extrair poses de v√≠deos √© muito lento (30-60 minutos para todos os v√≠deos).

**Solu√ß√£o**:
- Extrair poses **uma √∫nica vez** e salvar em disco (arquivos `.npz`)
- Carregar poses do disco para treinar (10-100x mais r√°pido!)

```bash
# Extrair poses (fazer uma vez)
poetry run python src/extract_poses.py

# Treinar (carrega do disco - r√°pido!)
poetry run python src/train_model.py
```

**Ganho**: De horas para minutos no treinamento!

### 2. Escalonamento por FPS

**Problema**: V√≠deos com diferentes FPS (30, 48, 60 fps) t√™m velocidades diferentes.

**Solu√ß√£o**: Ajustar automaticamente o tamanho da janela baseado no FPS:
- V√≠deo 30 fps: janela = 45 frames ‚Üí 1.5 segundos
- V√≠deo 60 fps: janela = 90 frames ‚Üí 1.5 segundos (mesma dura√ß√£o!)

**Benef√≠cio**: Consist√™ncia temporal entre v√≠deos de diferentes c√¢meras.

### 3. Remo√ß√£o da Classe "Neutro"

**Descoberta Cr√≠tica**:

‚ùå **Com classe "neutro"**:
```
Dados de treinamento:
  neutro: 9012 amostras (92%)  ‚Üê Esmagadora maioria
  forehand: 421 (4%)
  backhand: 347 (4%)

Resultado: Modelo aprende a sempre predizer "neutro" ‚Üí 0% precis√£o nos golpes!
```

‚úÖ **Sem classe "neutro"**:
```
Dados de treinamento:
  forehand: 420 (55%)  ‚Üê Balanceado
  backhand: 348 (45%)

Resultado: 83-88% de precis√£o nos golpes reais!
```

**Li√ß√£o**: Treinar apenas nos golpes anotados, n√£o nos frames vazios.

### 4. Rastreamento de Experimentos com MLflow

Todos os experimentos s√£o rastreados automaticamente:

| Par√¢metro | Exemplo |
|-----------|---------|
| window_size | 45 frames |
| learning_rate | 0.0005 |
| batch_size | 32 |
| fps_scaling | True |
| bidirectional | False |

| M√©trica | Exemplo |
|---------|---------|
| test_accuracy | 85.4% |
| f1_score | 0.87 |
| training_time | 8.5 min |

**Comparar resultados**:
```bash
poetry run mlflow ui
# Abrir http://localhost:5000
```

### 5. Grid Search Automatizado

Testar m√∫ltiplas configura√ß√µes automaticamente:

```bash
poetry run python src/grid_search.py --grid minimal
```

Testa combina√ß√µes de:
- Tamanhos de janela (30, 45, 60 frames)
- Learning rates (0.001, 0.0005, 0.0001)
- Arquiteturas (camadas LSTM, Bidirectional)
- Batch sizes (16, 32, 64)

**Resultado**: Encontra automaticamente a melhor configura√ß√£o.

---

## O Que o Modelo "V√™"

### Features Extra√≠das (132 por frame)

MediaPipe detecta **33 pontos do corpo**:

```
        Cabe√ßa (0)
           ‚Ä¢
           ‚îÇ
  (11)‚Ä¢‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚Ä¢(12)  ‚Üê Ombros
      ‚îÇ   ‚îÇ   ‚îÇ
  (13)‚Ä¢   ‚îÇ   ‚Ä¢(14)  ‚Üê Cotovelos
      ‚îÇ   ‚îÇ   ‚îÇ
  (15)‚Ä¢   ‚îÇ   ‚Ä¢(16)  ‚Üê Pulsos
           ‚îÇ
  (23)‚Ä¢‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚Ä¢(24)  ‚Üê Quadris
      ‚îÇ   ‚îÇ   ‚îÇ
  (25)‚Ä¢   ‚îÇ   ‚Ä¢(26)  ‚Üê Joelhos
```

**Cada ponto tem 4 valores**:
- `x`: posi√ß√£o horizontal (0-1)
- `y`: posi√ß√£o vertical (0-1)
- `z`: profundidade relativa
- `visibility`: confian√ßa da detec√ß√£o (0-1)

**Total**: 33 pontos √ó 4 valores = **132 features por frame**

### Como o Modelo Distingue Golpes

**Forehand** (direita para frente):
- Pulso direito: x aumenta (0.3 ‚Üí 0.7)
- Cotovelo direito: estende (z aumenta)
- Quadris: rota√ß√£o no sentido hor√°rio
- P√© esquerdo: planta e empurra

**Backhand** (esquerda para frente):
- Pulso esquerdo: x diminui (0.7 ‚Üí 0.3)
- Cotovelo esquerdo: estende
- Quadris: rota√ß√£o anti-hor√°ria
- P√© direito: planta e empurra

**O modelo aprende automaticamente** esses padr√µes dos dados de treinamento!

---

## Fluxo de Trabalho

### 1. Prepara√ß√£o dos Dados

```bash
# 1. Anotar v√≠deos no Label Studio
label-studio start

# 2. Verificar anota√ß√µes
poetry run python src/verify_annotation.py

# 3. Extrair poses (uma vez!)
poetry run python src/extract_poses.py
```

### 2. Treinamento

```bash
# Treinamento simples
poetry run python src/train_model.py

# Grid search (testar m√∫ltiplas configura√ß√µes)
poetry run python src/grid_search.py --grid minimal
```

### 3. Detec√ß√£o em Novos V√≠deos

```bash
poetry run python src/detect_strokes.py video.mp4
```

**Sa√≠das geradas**:
- `video_timeline.png` - Timeline visual colorido
- `video_report.txt` - Relat√≥rio com timestamps
- `video_strokes.json` - Dados em JSON

### 4. An√°lise de Resultados

```bash
# Abrir interface do MLflow
poetry run mlflow ui
```

Comparar:
- Acur√°cia entre diferentes configura√ß√µes
- F1-score por classe
- Matrizes de confus√£o
- Tempo de treinamento

---

## Destaques T√©cnicos

### 1. Janelas Deslizantes com Sobreposi√ß√£o

```
V√≠deo: [frame 0, frame 1, frame 2, ..., frame 300]

Janela 1: frames 0-44   (45 frames)
Janela 2: frames 23-67  (overlap de 22 frames)
Janela 3: frames 46-90
...
```

**Por qu√™ 50% de sobreposi√ß√£o?**
- Captura golpes que come√ßam no meio de uma janela
- Gera mais amostras de treinamento
- Detec√ß√£o mais precisa durante infer√™ncia

### 2. Vota√ß√£o por Maioria para Labels

```
Janela: frames 30-74 (45 frames)
Labels: [F, F, F, F, ..., B, B, B]
        ‚îÇ   ‚îî‚îÄ 30 frames forehand
        ‚îî‚îÄ 15 frames backhand

Contagem:
  forehand: 30 (67%)
  backhand: 15 (33%)

Resultado: Label = FOREHAND (maioria > 50%)
```

### 3. P√≥s-processamento Inteligente

**Problema**: Janelas deslizantes geram m√∫ltiplas detec√ß√µes do mesmo golpe.

**Solu√ß√£o**: Mesclar detec√ß√µes pr√≥ximas
```
Detec√ß√µes brutas (antes):
  Forehand: frames 30-74  (conf: 88%)
  Forehand: frames 35-79  (conf: 92%)
  Forehand: frames 40-84  (conf: 85%)

Ap√≥s mesclagem:
  Forehand: frames 30-84  (conf m√©dia: 88.3%)
```

### 4. Filtragem por Confian√ßa e Dura√ß√£o

```python
CONFIG = {
    'confidence_threshold': 0.7,  # M√≠nimo 70% de confian√ßa
    'min_stroke_duration': 13,    # M√≠nimo 13 frames
}
```

**Filtra**:
- Predi√ß√µes com baixa confian√ßa (< 70%)
- Detec√ß√µes muito curtas (< 13 frames = ~0.4 segundos)

---

## Otimiza√ß√µes Dispon√≠veis

### 1. Balanceamento de Classes

```python
# Pesos autom√°ticos para classes desbalanceadas
class_weights = compute_class_weight('balanced', classes, y_train)
```

**Benef√≠cio**: Classes minorit√°rias recebem mais peso no treinamento.

### 2. LSTM Bidirecional

```python
CONFIG = {
    'use_bidirectional': True,  # Processa sequ√™ncia nas duas dire√ß√µes
}
```

**Ganho esperado**: +2-3% em F1-score
**Custo**: Treinamento ~2x mais lento

### 3. Ajuste de Hiperpar√¢metros

| Par√¢metro | Valor Padr√£o | Quando Aumentar | Quando Diminuir |
|-----------|--------------|-----------------|-----------------|
| window_size | 45 | Golpes lentos | Golpes r√°pidos |
| learning_rate | 0.0005 | Treino inst√°vel | Converg√™ncia lenta |
| batch_size | 32 | Mais GPU/RAM | Menos mem√≥ria |
| dropout | 0.4 | Overfitting | Underfitting |

### 4. Pr√©-processamento de V√≠deos

Para v√≠deos escuros ou com jogador pequeno:

```bash
poetry run python src/preprocess_video.py input.mp4 output.mp4 \
    --auto-brighten \
    --static-zoom 1.5 \
    --fisheye
```

**Melhora**: Detec√ß√£o de pose de 55% ‚Üí 90%!

---

## Resultados Esperados

### Acur√°cia T√≠pica

| Cen√°rio | Acur√°cia | F1-Score |
|---------|----------|----------|
| Dataset balanceado | 83-88% | 0.85-0.88 |
| Com otimiza√ß√µes | 85-92% | 0.87-0.91 |
| Bidirectional LSTM | +2-3% | +0.02-0.03 |

### Tempo de Execu√ß√£o

| Tarefa | CPU | GPU |
|--------|-----|-----|
| Extra√ß√£o de poses (15 v√≠deos) | 60 min | 30 min |
| Treinamento (150 epochs) | 30 min | 8 min |
| Detec√ß√£o (v√≠deo 5 min) | 3 min | 1 min |

### Exemplo de Sa√≠da

```
Relat√≥rio de An√°lise - Partida de T√™nis
========================================

V√≠deo: match_001.mp4
Dura√ß√£o: 5:23 (323 segundos)
Golpes detectados: 47

Timeline de Golpes:
  00:12.3 - 00:13.8 | Forehand (conf: 0.92)
  00:15.1 - 00:16.4 | Backhand (conf: 0.87)
  00:19.7 - 00:21.0 | Forehand (conf: 0.91)
  ...

Estat√≠sticas:
  Forehand: 24 (51.1%)
  Backhand: 23 (48.9%)
```

---

## Por Que Esta Abordagem Funciona

### 1. Features Baseadas em Pose (n√£o pixels brutos)

**Vantagens**:
- ‚úÖ **47.000x menor** que v√≠deo bruto (132 vs 6.2M features)
- ‚úÖ **Invariante √† c√¢mera** (funciona de qualquer √¢ngulo)
- ‚úÖ **Invariante √† ilumina√ß√£o** (dia ou noite)
- ‚úÖ **Foco no movimento** (ignora fundo, roupa, etc.)
- ‚úÖ **Menos dados necess√°rios** para treinar

### 2. LSTM para Padr√µes Temporais

```
Frame 0:  Pulso atr√°s    ‚Üí LSTM lembra: "prepara√ß√£o"
Frame 15: Pulso no meio  ‚Üí LSTM lembra: "acelera√ß√£o"
Frame 30: Pulso √† frente ‚Üí LSTM conclui: "FOREHAND!"
```

**Outras arquiteturas**:
- CNN: Boa para imagens, n√£o para sequ√™ncias
- RNN simples: Esquece frames antigos (vanishing gradient)
- Transformer: Precisa de mais dados

**LSTM √© ideal** para este caso de uso!

### 3. Sistema em Duas Etapas

**Etapa 1 - Treinamento**:
- Foco: "O que √© este golpe?"
- Dados: Apenas segmentos anotados
- Objetivo: Classifica√ß√£o pura

**Etapa 2 - Infer√™ncia**:
- Foco: "Quando os golpes ocorrem?"
- Dados: V√≠deo cont√≠nuo completo
- Objetivo: Detec√ß√£o + classifica√ß√£o

**Benef√≠cio**: Cada etapa otimizada para seu objetivo espec√≠fico.

---

## Li√ß√µes Aprendidas

### ‚úÖ O Que Funcionou

1. **Remover classe "neutro"** - Breakthrough de 54% ‚Üí 85% acur√°cia
2. **Cache de poses** - 100x mais r√°pido experimentar
3. **Janelas com sobreposi√ß√£o** - Detec√ß√£o mais robusta
4. **MLflow tracking** - Experimentos organizados e reproduz√≠veis
5. **Escalonamento por FPS** - Consist√™ncia entre v√≠deos

### ‚ùå O Que N√£o Funcionou

1. **Incluir classe "neutro"** - Desbalanceamento massivo (92% neutro)
2. **Processar todos os frames** - Desperdi√ßa tempo em n√£o-golpes
3. **TensorFlow GPU via Poetry** - Conflitos de depend√™ncias
4. **Janelas sem sobreposi√ß√£o** - Perde golpes nas bordas

### üí° Decis√µes de Design

**Por que 45 frames?**
- Golpes de t√™nis duram 0.5-1.5 segundos
- 45 frames @ 30fps = 1.5 segundos
- Captura golpe completo (prepara√ß√£o ‚Üí contato ‚Üí finaliza√ß√£o)

**Por que dropout 0.4?**
- Datasets pequenos tendem a overfit
- Dropout alto (0.4) for√ßa generaliza√ß√£o
- Reduz overfitting sem prejudicar muito o treino

**Por que stride=5 na detec√ß√£o?**
- Verifica a cada ~0.16 segundos
- Detec√ß√£o precisa de in√≠cio/fim do golpe
- Custo computacional aceit√°vel

---

## Pr√≥ximos Passos e Melhorias Futuras

### Curto Prazo

1. **Aumenta√ß√£o de dados** - Time warping, espelhamento
2. **Mecanismo de aten√ß√£o** - Focar em frames importantes
3. **Ensemble de modelos** - Combinar m√∫ltiplos modelos

### M√©dio Prazo

4. **Avalia√ß√£o de qualidade** - "Qu√£o bom foi o golpe?"
5. **Rastreamento de m√∫ltiplos jogadores** - Duplas
6. **Integra√ß√£o com rastreamento de bola** - Melhor timing

### Longo Prazo

7. **Infer√™ncia em tempo real** - Streaming ao vivo
8. **Deploy mobile** - TensorFlow Lite para smartphones
9. **Transfer learning** - Pr√©-treino em datasets grandes

---

## Comandos Essenciais

```bash
# Instala√ß√£o
poetry install

# Extra√ß√£o de poses (uma vez)
poetry run python src/extract_poses.py

# Treinar modelo
poetry run python src/train_model.py

# Detectar golpes
poetry run python src/detect_strokes.py video.mp4

# Grid search
poetry run python src/grid_search.py --grid minimal

# Interface MLflow
poetry run mlflow ui

# Pr√©-processar v√≠deos
poetry run python src/preprocess_video.py input.mp4 output.mp4 --auto-brighten
```

---

## Estrutura do Projeto

```
video_tennis_analysis/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ train_model.py          # Treinamento principal
‚îÇ   ‚îú‚îÄ‚îÄ detect_strokes.py       # Detec√ß√£o em v√≠deos
‚îÇ   ‚îú‚îÄ‚îÄ extract_poses.py        # Extra√ß√£o de poses (cache)
‚îÇ   ‚îú‚îÄ‚îÄ grid_search.py          # Busca de hiperpar√¢metros
‚îÇ   ‚îî‚îÄ‚îÄ verify_annotation.py    # Verificar anota√ß√µes
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ videos/                 # V√≠deos de treinamento (720p recomendado)
‚îú‚îÄ‚îÄ label_studio_exports/       # Anota√ß√µes JSON do Label Studio
‚îú‚îÄ‚îÄ pose_data/                  # Poses extra√≠das (.npz)
‚îú‚îÄ‚îÄ output/                     # Modelo treinado + m√©tricas
‚îú‚îÄ‚îÄ analysis_output/            # Resultados de detec√ß√£o
‚îú‚îÄ‚îÄ mlruns/                     # Dados do MLflow
‚îî‚îÄ‚îÄ documentacao/               # Documenta√ß√£o completa (10 arquivos)
    ‚îú‚îÄ‚îÄ README_DOCS.md          # √çndice de navega√ß√£o
    ‚îú‚îÄ‚îÄ 00_GETTING_STARTED.md   # In√≠cio r√°pido
    ‚îî‚îÄ‚îÄ ...                     # Guias detalhados
```

---

## Requisitos do Sistema

**M√≠nimos**:
- Python 3.11+
- 4GB RAM
- 10GB espa√ßo em disco

**Recomendados**:
- GPU CUDA (10x mais r√°pido)
- 8GB+ RAM
- 20GB+ espa√ßo em disco

**Depend√™ncias principais**:
- TensorFlow 2.17-2.18
- MediaPipe 0.10.21
- MLflow
- OpenCV

---

## Refer√™ncias

### Documenta√ß√£o Completa

Veja [documentacao/README_DOCS.md](README_DOCS.md) para:
- Guia de in√≠cio r√°pido
- Arquitetura detalhada
- Otimiza√ß√£o de modelos
- Grid search avan√ßado
- Rastreamento MLflow
- E mais 5 guias especializados

### Come√ßar Agora

```bash
# 1. Instalar
poetry install

# 2. Ler o guia de in√≠cio
cat documentacao/00_GETTING_STARTED.md

# 3. Treinar seu primeiro modelo
poetry run python src/train_model.py

# 4. Detectar golpes
poetry run python src/detect_strokes.py seu_video.mp4
```

---

**Desenvolvido para an√°lise de desempenho em t√™nis usando Machine Learning** üéæ
